{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11518941,"sourceType":"datasetVersion","datasetId":7224184}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install hf_xet","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T21:04:35.334520Z","iopub.execute_input":"2025-04-22T21:04:35.334890Z","iopub.status.idle":"2025-04-22T21:04:39.037988Z","shell.execute_reply.started":"2025-04-22T21:04:35.334864Z","shell.execute_reply":"2025-04-22T21:04:39.036941Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: hf_xet in /usr/local/lib/python3.11/dist-packages (1.0.3)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"import pandas as pd\nfrom datasets import Dataset\nfrom transformers import T5Tokenizer, T5ForConditionalGeneration, Seq2SeqTrainer, Seq2SeqTrainingArguments","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-22T21:04:40.566128Z","iopub.execute_input":"2025-04-22T21:04:40.566504Z","iopub.status.idle":"2025-04-22T21:04:40.572079Z","shell.execute_reply.started":"2025-04-22T21:04:40.566474Z","shell.execute_reply":"2025-04-22T21:04:40.571068Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"import torch","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T21:04:41.935560Z","iopub.execute_input":"2025-04-22T21:04:41.935909Z","iopub.status.idle":"2025-04-22T21:04:41.940609Z","shell.execute_reply.started":"2025-04-22T21:04:41.935885Z","shell.execute_reply":"2025-04-22T21:04:41.939592Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"# Load the dataset from the CSV file\ndf = pd.read_csv('/kaggle/input/password-pair-dataset/password_dataset_2.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T21:04:47.813217Z","iopub.execute_input":"2025-04-22T21:04:47.813550Z","iopub.status.idle":"2025-04-22T21:04:47.833847Z","shell.execute_reply.started":"2025-04-22T21:04:47.813528Z","shell.execute_reply":"2025-04-22T21:04:47.832948Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T21:04:49.072661Z","iopub.execute_input":"2025-04-22T21:04:49.072999Z","iopub.status.idle":"2025-04-22T21:04:49.084122Z","shell.execute_reply.started":"2025-04-22T21:04:49.072978Z","shell.execute_reply":"2025-04-22T21:04:49.083196Z"}},"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"                                               input         output\n0  You are a security expert helping users streng...   P@$$wOrd123!\n1  You are a security expert helping users streng...       123$AbC!\n2  You are a security expert helping users streng...      P@$$wOrd8\n3  You are a security expert helping users streng...  1L3tr!c4l1234\n4  You are a security expert helping users streng...    QwertY1!@#$","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>input</th>\n      <th>output</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>You are a security expert helping users streng...</td>\n      <td>P@$$wOrd123!</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>You are a security expert helping users streng...</td>\n      <td>123$AbC!</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>You are a security expert helping users streng...</td>\n      <td>P@$$wOrd8</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>You are a security expert helping users streng...</td>\n      <td>1L3tr!c4l1234</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>You are a security expert helping users streng...</td>\n      <td>QwertY1!@#$</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":23},{"cell_type":"code","source":"# Convert the DataFrame to a Hugging Face dataset\ndataset = Dataset.from_pandas(df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T21:04:50.592086Z","iopub.execute_input":"2025-04-22T21:04:50.592394Z","iopub.status.idle":"2025-04-22T21:04:50.604949Z","shell.execute_reply.started":"2025-04-22T21:04:50.592372Z","shell.execute_reply":"2025-04-22T21:04:50.603964Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"# Initialize the tokenizer and model\nmodel_name = 'google/flan-t5-base'\ntokenizer = T5Tokenizer.from_pretrained(model_name)\nmodel = T5ForConditionalGeneration.from_pretrained(model_name)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T21:04:51.507571Z","iopub.execute_input":"2025-04-22T21:04:51.507914Z","iopub.status.idle":"2025-04-22T21:04:52.174375Z","shell.execute_reply.started":"2025-04-22T21:04:51.507890Z","shell.execute_reply":"2025-04-22T21:04:52.173545Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"# Preprocessing function\ndef preprocess_function(examples):\n    # Tokenizing the input text and output text\n    inputs = tokenizer(examples['input'], max_length=512, padding=\"max_length\", truncation=True)\n    targets = tokenizer(examples['output'], max_length=128, padding=\"max_length\", truncation=True)\n    \n    # Return tokenized inputs and labels\n    inputs['labels'] = targets['input_ids']\n    inputs['labels'] = [\n        [(label if label != tokenizer.pad_token_id else -100) for label in labels]\n        for labels in inputs['labels']\n    ]\n    return inputs","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T21:04:53.966074Z","iopub.execute_input":"2025-04-22T21:04:53.966387Z","iopub.status.idle":"2025-04-22T21:04:53.972675Z","shell.execute_reply.started":"2025-04-22T21:04:53.966364Z","shell.execute_reply":"2025-04-22T21:04:53.971663Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"# Apply the preprocessing function\nencoded_dataset = dataset.map(preprocess_function, batched=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T21:04:56.292340Z","iopub.execute_input":"2025-04-22T21:04:56.293222Z","iopub.status.idle":"2025-04-22T21:04:56.358554Z","shell.execute_reply.started":"2025-04-22T21:04:56.293186Z","shell.execute_reply":"2025-04-22T21:04:56.357576Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/10 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7f333d57878b4dc6ac1e546cb320bb2c"}},"metadata":{}}],"execution_count":27},{"cell_type":"code","source":"training_args = Seq2SeqTrainingArguments(\n    output_dir='/kaggle/working/result',\n    eval_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    learning_rate=2e-5,\n    per_device_train_batch_size=8,\n    per_device_eval_batch_size=8,\n    num_train_epochs=3,\n    weight_decay=0.01,\n    logging_dir='/kaggle/working/logs',\n    logging_steps=10,\n    logging_first_step=True,\n    save_steps=500,\n    save_total_limit=3,\n    load_best_model_at_end=True,\n    predict_with_generate=True,\n    report_to=[]  # Explicitly disable all logging integrations\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T21:09:44.367592Z","iopub.execute_input":"2025-04-22T21:09:44.368392Z","iopub.status.idle":"2025-04-22T21:09:44.374595Z","shell.execute_reply.started":"2025-04-22T21:09:44.368361Z","shell.execute_reply":"2025-04-22T21:09:44.373573Z"}},"outputs":[],"execution_count":32},{"cell_type":"code","source":"trainer = Seq2SeqTrainer(\n    model=model,\n    args=training_args,\n    train_dataset=encoded_dataset,\n    eval_dataset=encoded_dataset,\n    tokenizer=tokenizer\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T21:09:49.982682Z","iopub.execute_input":"2025-04-22T21:09:49.983038Z","iopub.status.idle":"2025-04-22T21:09:50.002295Z","shell.execute_reply.started":"2025-04-22T21:09:49.983014Z","shell.execute_reply":"2025-04-22T21:09:50.001354Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_31/1050800592.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n  trainer = Seq2SeqTrainer(\n","output_type":"stream"}],"execution_count":33},{"cell_type":"code","source":"# Fine-tune the model\ntrainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T21:09:52.867460Z","iopub.execute_input":"2025-04-22T21:09:52.867817Z","iopub.status.idle":"2025-04-22T21:13:37.929681Z","shell.execute_reply.started":"2025-04-22T21:09:52.867795Z","shell.execute_reply":"2025-04-22T21:13:37.928817Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [6/6 02:58, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>5.743000</td>\n      <td>5.446252</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>5.743000</td>\n      <td>5.295423</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>5.743000</td>\n      <td>5.239777</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"There were missing keys in the checkpoint model loaded: ['encoder.embed_tokens.weight', 'decoder.embed_tokens.weight'].\n","output_type":"stream"},{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=6, training_loss=5.6536290645599365, metrics={'train_runtime': 224.5166, 'train_samples_per_second': 0.134, 'train_steps_per_second': 0.027, 'total_flos': 20542720573440.0, 'train_loss': 5.6536290645599365, 'epoch': 3.0})"},"metadata":{}}],"execution_count":34},{"cell_type":"code","source":"# Save the fine-tuned model\nmodel.save_pretrained('/kaggle/working/fine_tuned_model')\ntokenizer.save_pretrained('/kaggle/working/fine_tuned_model')\nprint(\"Fine-tuning completed and model saved.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T21:13:44.995452Z","iopub.execute_input":"2025-04-22T21:13:44.995809Z","iopub.status.idle":"2025-04-22T21:13:46.309318Z","shell.execute_reply.started":"2025-04-22T21:13:44.995783Z","shell.execute_reply":"2025-04-22T21:13:46.308115Z"}},"outputs":[{"name":"stdout","text":"Fine-tuning completed and model saved.\n","output_type":"stream"}],"execution_count":35},{"cell_type":"code","source":"!zip -r /kaggle/working/fine_tuned_model.zip /kaggle/working/fine_tuned_model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T21:19:45.353830Z","iopub.execute_input":"2025-04-22T21:19:45.358056Z","iopub.status.idle":"2025-04-22T21:20:45.554401Z","shell.execute_reply.started":"2025-04-22T21:19:45.357988Z","shell.execute_reply":"2025-04-22T21:20:45.553050Z"}},"outputs":[{"name":"stdout","text":"  adding: kaggle/working/fine_tuned_model/ (stored 0%)\n  adding: kaggle/working/fine_tuned_model/config.json (deflated 62%)\n  adding: kaggle/working/fine_tuned_model/tokenizer_config.json (deflated 94%)\n  adding: kaggle/working/fine_tuned_model/spiece.model (deflated 48%)\n  adding: kaggle/working/fine_tuned_model/model.safetensors (deflated 7%)\n  adding: kaggle/working/fine_tuned_model/added_tokens.json (deflated 83%)\n  adding: kaggle/working/fine_tuned_model/special_tokens_map.json (deflated 85%)\n  adding: kaggle/working/fine_tuned_model/generation_config.json (deflated 29%)\n","output_type":"stream"}],"execution_count":36},{"cell_type":"code","source":"# Load and generate passwords","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\nfrom zxcvbn import zxcvbn\n# import torch\n\n# 1. Load fine-tuned model and tokenizer\nmodel_path = \"/kaggle/working/fine_tuned_model\"  # change this if saved elsewhere\ntokenizer = AutoTokenizer.from_pretrained(model_path)\nmodel = AutoModelForSeq2SeqLM.from_pretrained(model_path)\n\n# # Set model to eval mode and select device\n# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n# model.to(device)\n# model.eval()\n\ndef analyze_password(pw: str) -> str:\n    \"\"\"Returns prompt string from zxcvbn feedback for given weak password\"\"\"\n    feedback = zxcvbn(pw)\n    entropy = feedback[\"entropy\"]\n    warnings = feedback[\"feedback\"][\"warning\"]\n    suggestions = feedback[\"feedback\"][\"suggestions\"]\n    guess_info = []\n\n    if feedback[\"sequence\"]:\n        for item in feedback[\"sequence\"]:\n            if \"dictionary_name\" in item:\n                guess_info.append(f\"- '{item['token']}' is a common {item['dictionary_name']} word\")\n            elif item.get(\"pattern\") == \"repeat\":\n                guess_info.append(\"- Password has repeated characters\")\n            elif item.get(\"pattern\") == \"sequence\":\n                guess_info.append(\"- Password has sequential characters\")\n\n    if entropy < 30:\n        guess_info.append(\"- Password has low entropy\")\n    if not any(c in pw for c in \"!@#$%^&*()_+-=[]{}|;:,.<>?/\"):\n        guess_info.append(\"- Missing special characters\")\n\n    prompt = f\"\"\"\nYou are a security expert helping users strengthen their passwords using NIST guidelines.\nHere is the analysis of a weak password:\nPassword: \"{pw}\"\nEntropy: {entropy:.2f}\nIdentified Weaknesses:\n{chr(10).join(guess_info) or \"- None\"}\n\nZxcvbn Feedback:\nWarning: {warnings or \"None\"}\nSuggestions: {' '.join(suggestions) if suggestions else 'None'}\n\nYour task:\n- Improve the password while keeping its original idea.\n- Avoid dictionary words, predictable patterns, and weak structures.\n- Ensure it includes uppercase, lowercase, digits, and special characters.\n- Ensure a uniform distribution of these character sets to increase the unpredictability of your password.\n- Create a password that is both **strong** and **memorable**.\n- Return only the improved password (no explanations).\n\"\"\".strip()\n\n    return prompt\n\ndef generate_strong_password(weak_pw: str) -> str:\n    \"\"\"Generate strong password from weak one using the fine-tuned model\"\"\"\n    prompt = analyze_password(weak_pw)\n    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True).to(device)\n\n    outputs = model.generate(\n        **inputs,\n        max_length=64,\n        do_sample=True,\n        top_p=0.95,\n        top_k=50,\n        temperature=0.8\n    )\n    strong_pw = tokenizer.decode(outputs[0], skip_special_tokens=True)\n    return strong_pw.strip()\n\n# 2. Interactive loop\nwhile True:\n    weak = input(\"\\nEnter a weak password (or type 'exit'): \").strip()\n    if weak.lower() == \"exit\":\n        break\n\n    print(\"\\nüìâ Analyzing your password...\")\n    original_feedback = zxcvbn(weak)\n    print(f\"Original Entropy: {original_feedback['entropy']:.2f}\")\n    print(f\"Score: {original_feedback['score']}/4\")\n\n    # 3-5. Generate stronger version\n    strong = generate_strong_password(weak)\n    print(f\"\\nüîê Suggested Strong Password: {strong}\")\n\n    # 6. Re-analyze new password\n    new_feedback = zxcvbn(strong)\n    print(f\"\\nüìà Improved Entropy: {new_feedback['entropy']:.2f}\")\n    print(f\"New Score: {new_feedback['score']}/4\")\n    print(\"-\" * 40)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}