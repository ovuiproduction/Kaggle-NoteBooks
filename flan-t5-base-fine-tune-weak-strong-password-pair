{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11530740,"sourceType":"datasetVersion","datasetId":7232280},{"sourceId":11531922,"sourceType":"datasetVersion","datasetId":7232971}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nfrom datasets import Dataset\nfrom transformers import T5Tokenizer, T5ForConditionalGeneration, Seq2SeqTrainer, Seq2SeqTrainingArguments\nimport torch","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-23T16:39:07.518314Z","iopub.execute_input":"2025-04-23T16:39:07.518625Z","iopub.status.idle":"2025-04-23T16:39:43.363588Z","shell.execute_reply.started":"2025-04-23T16:39:07.518601Z","shell.execute_reply":"2025-04-23T16:39:43.362643Z"}},"outputs":[{"name":"stderr","text":"2025-04-23 16:39:26.769416: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1745426367.024677      31 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1745426367.100439      31 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# Load the dataset from the CSV file\ndf = pd.read_csv('/kaggle/input/password-dataset-small/password_dataset_small.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-23T16:39:43.365111Z","iopub.execute_input":"2025-04-23T16:39:43.365790Z","iopub.status.idle":"2025-04-23T16:39:43.398859Z","shell.execute_reply.started":"2025-04-23T16:39:43.365735Z","shell.execute_reply":"2025-04-23T16:39:43.397956Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-23T16:39:43.399958Z","iopub.execute_input":"2025-04-23T16:39:43.400311Z","iopub.status.idle":"2025-04-23T16:39:43.451193Z","shell.execute_reply.started":"2025-04-23T16:39:43.400283Z","shell.execute_reply":"2025-04-23T16:39:43.450120Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"                                               input         output\n0  You are a security expert helping users streng...     Spr!nt2024\n1  You are a security expert helping users streng...    ThAnKs123!@\n2  You are a security expert helping users streng...   j3r!ch0_f4ll\n3  You are a security expert helping users streng...  T0p$ecr3t2030\n4  You are a security expert helping users streng...   Gr4c3!Fl0w3r","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>input</th>\n      <th>output</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>You are a security expert helping users streng...</td>\n      <td>Spr!nt2024</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>You are a security expert helping users streng...</td>\n      <td>ThAnKs123!@</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>You are a security expert helping users streng...</td>\n      <td>j3r!ch0_f4ll</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>You are a security expert helping users streng...</td>\n      <td>T0p$ecr3t2030</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>You are a security expert helping users streng...</td>\n      <td>Gr4c3!Fl0w3r</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"# Convert the DataFrame to a Hugging Face dataset\ndataset = Dataset.from_pandas(df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-23T16:39:43.452955Z","iopub.execute_input":"2025-04-23T16:39:43.453254Z","iopub.status.idle":"2025-04-23T16:39:43.479920Z","shell.execute_reply.started":"2025-04-23T16:39:43.453232Z","shell.execute_reply":"2025-04-23T16:39:43.479004Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# Initialize the tokenizer and model\nmodel_name = 'google/flan-t5-base'\ntokenizer = T5Tokenizer.from_pretrained(model_name)\nmodel = T5ForConditionalGeneration.from_pretrained(model_name)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-23T16:39:43.480718Z","iopub.execute_input":"2025-04-23T16:39:43.481069Z","iopub.status.idle":"2025-04-23T16:39:50.321293Z","shell.execute_reply.started":"2025-04-23T16:39:43.481037Z","shell.execute_reply":"2025-04-23T16:39:50.320357Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/2.54k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"27f56fa9ce8c4de4a42edbf3ab78d345"}},"metadata":{}},{"name":"stderr","text":"Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"afb6db723a004ed8b1efe9e3f70a53c5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b2620fbe4bed4686ab8e326743b017fa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f17185f9727c43a593f076ac1ac5cc0c"}},"metadata":{}},{"name":"stderr","text":"You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.40k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e0cee0fbe35d489e91d138e7ac46b8cc"}},"metadata":{}},{"name":"stderr","text":"Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/990M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0cca9dfb0cb44b9183df3dfc25686ed1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d74e7eeb44c94cc1968b4347eb4c11ea"}},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"# Preprocessing function\ndef preprocess_function(examples):\n    # Tokenizing the input text and output text\n    inputs = tokenizer(examples['input'], max_length=512, padding=\"max_length\", truncation=True)\n    targets = tokenizer(examples['output'], max_length=128, padding=\"max_length\", truncation=True)\n    \n    # Return tokenized inputs and labels\n    inputs['labels'] = targets['input_ids']\n    inputs['labels'] = [\n        [(label if label != tokenizer.pad_token_id else -100) for label in labels]\n        for labels in inputs['labels']\n    ]\n    return inputs","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-23T16:39:50.322376Z","iopub.execute_input":"2025-04-23T16:39:50.322697Z","iopub.status.idle":"2025-04-23T16:39:50.328871Z","shell.execute_reply.started":"2025-04-23T16:39:50.322667Z","shell.execute_reply":"2025-04-23T16:39:50.327970Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# Apply the preprocessing function\nencoded_dataset = dataset.map(preprocess_function, batched=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-23T16:39:50.329728Z","iopub.execute_input":"2025-04-23T16:39:50.330068Z","iopub.status.idle":"2025-04-23T16:39:51.282940Z","shell.execute_reply.started":"2025-04-23T16:39:50.330036Z","shell.execute_reply":"2025-04-23T16:39:51.281942Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/499 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dda6c33267c94ea5bb1be1bea409c032"}},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"training_args = Seq2SeqTrainingArguments(\n    output_dir='/kaggle/working/result',\n    eval_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    learning_rate=2e-5,\n    per_device_train_batch_size=8,\n    per_device_eval_batch_size=8,\n    num_train_epochs=3,\n    weight_decay=0.01,\n    logging_dir='/kaggle/working/logs',\n    logging_steps=10,\n    logging_first_step=True,\n    save_steps=500,\n    save_total_limit=3,\n    load_best_model_at_end=True,\n    predict_with_generate=True,\n    report_to=[]\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-23T16:39:51.284169Z","iopub.execute_input":"2025-04-23T16:39:51.284642Z","iopub.status.idle":"2025-04-23T16:39:51.294051Z","shell.execute_reply.started":"2025-04-23T16:39:51.284619Z","shell.execute_reply":"2025-04-23T16:39:51.293223Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"trainer = Seq2SeqTrainer(\n    model=model,\n    args=training_args,\n    train_dataset=encoded_dataset,\n    eval_dataset=encoded_dataset,\n    tokenizer=tokenizer\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-23T16:39:51.294908Z","iopub.execute_input":"2025-04-23T16:39:51.295218Z","iopub.status.idle":"2025-04-23T16:39:51.327472Z","shell.execute_reply.started":"2025-04-23T16:39:51.295179Z","shell.execute_reply":"2025-04-23T16:39:51.326471Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_31/1050800592.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n  trainer = Seq2SeqTrainer(\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# Fine-tune the model\ntrainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-23T16:39:51.329796Z","iopub.execute_input":"2025-04-23T16:39:51.330031Z","iopub.status.idle":"2025-04-23T19:47:24.827458Z","shell.execute_reply.started":"2025-04-23T16:39:51.330014Z","shell.execute_reply":"2025-04-23T19:47:24.825590Z"}},"outputs":[{"name":"stderr","text":"Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='189' max='189' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [189/189 3:06:27, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>3.769100</td>\n      <td>3.442617</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>3.361600</td>\n      <td>2.983704</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>3.211700</td>\n      <td>2.892132</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"There were missing keys in the checkpoint model loaded: ['encoder.embed_tokens.weight', 'decoder.embed_tokens.weight'].\n","output_type":"stream"},{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=189, training_loss=3.715092146838153, metrics={'train_runtime': 11253.0148, 'train_samples_per_second': 0.133, 'train_steps_per_second': 0.017, 'total_flos': 1025081756614656.0, 'train_loss': 3.715092146838153, 'epoch': 3.0})"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"# Save the fine-tuned model\nmodel.save_pretrained('/kaggle/working/fine_tuned_model')\ntokenizer.save_pretrained('/kaggle/working/fine_tuned_model')\nprint(\"Fine-tuning completed and model saved.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-23T19:47:24.830311Z","iopub.execute_input":"2025-04-23T19:47:24.830814Z","iopub.status.idle":"2025-04-23T19:47:27.316604Z","shell.execute_reply.started":"2025-04-23T19:47:24.830764Z","shell.execute_reply":"2025-04-23T19:47:27.314191Z"}},"outputs":[{"name":"stdout","text":"Fine-tuning completed and model saved.\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"!zip -r /kaggle/working/fine_tuned_model.zip /kaggle/working/fine_tuned_model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-23T19:47:27.317734Z","iopub.execute_input":"2025-04-23T19:47:27.318205Z","iopub.status.idle":"2025-04-23T19:48:30.121128Z","shell.execute_reply.started":"2025-04-23T19:47:27.318180Z","shell.execute_reply":"2025-04-23T19:48:30.119715Z"}},"outputs":[{"name":"stdout","text":"  adding: kaggle/working/fine_tuned_model/ (stored 0%)\n  adding: kaggle/working/fine_tuned_model/special_tokens_map.json (deflated 85%)\n  adding: kaggle/working/fine_tuned_model/generation_config.json (deflated 29%)\n  adding: kaggle/working/fine_tuned_model/added_tokens.json (deflated 83%)\n  adding: kaggle/working/fine_tuned_model/model.safetensors (deflated 7%)\n  adding: kaggle/working/fine_tuned_model/tokenizer_config.json (deflated 94%)\n  adding: kaggle/working/fine_tuned_model/spiece.model (deflated 48%)\n  adding: kaggle/working/fine_tuned_model/config.json (deflated 62%)\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"# Load and generate passwords","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# pip install zxcvbn","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-23T20:19:18.997638Z","iopub.execute_input":"2025-04-23T20:19:18.998793Z","iopub.status.idle":"2025-04-23T20:19:25.676691Z","shell.execute_reply.started":"2025-04-23T20:19:18.998728Z","shell.execute_reply":"2025-04-23T20:19:25.675336Z"}},"outputs":[{"name":"stdout","text":"Collecting zxcvbn\n  Downloading zxcvbn-4.5.0-py2.py3-none-any.whl.metadata (5.9 kB)\nDownloading zxcvbn-4.5.0-py2.py3-none-any.whl (409 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m409.4/409.4 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: zxcvbn\nSuccessfully installed zxcvbn-4.5.0\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"# from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n# from zxcvbn import zxcvbn","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-23T20:25:01.820329Z","iopub.execute_input":"2025-04-23T20:25:01.821459Z","iopub.status.idle":"2025-04-23T20:25:01.883928Z","shell.execute_reply.started":"2025-04-23T20:25:01.821421Z","shell.execute_reply":"2025-04-23T20:25:01.882933Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"# # 1. Load fine-tuned model and tokenizer\n# model_path = \"/kaggle/working/fine_tuned_model\"  # change this if saved elsewhere\n# tokenizer = AutoTokenizer.from_pretrained(model_path)\n# model = AutoModelForSeq2SeqLM.from_pretrained(model_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-23T20:25:02.757348Z","iopub.execute_input":"2025-04-23T20:25:02.757709Z","iopub.status.idle":"2025-04-23T20:25:03.838922Z","shell.execute_reply.started":"2025-04-23T20:25:02.757683Z","shell.execute_reply":"2025-04-23T20:25:03.837805Z"}},"outputs":[{"name":"stderr","text":"You set `add_prefix_space`. The tokenizer needs to be converted from the slow tokenizers\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"\n# def analyze_password(pw: str) -> str:\n#     \"\"\"Returns prompt string from zxcvbn feedback for given weak password\"\"\"\n#     feedback = zxcvbn(pw)\n#     entropy = feedback[\"guesses_log10\"]\n#     warnings = feedback[\"feedback\"][\"warning\"]\n#     suggestions = feedback[\"feedback\"][\"suggestions\"]\n#     guess_info = []\n\n#     if feedback[\"sequence\"]:\n#         for item in feedback[\"sequence\"]:\n#             if \"dictionary_name\" in item:\n#                 guess_info.append(f\"- '{item['token']}' is a common {item['dictionary_name']} word\")\n#             elif item.get(\"pattern\") == \"repeat\":\n#                 guess_info.append(\"- Password has repeated characters\")\n#             elif item.get(\"pattern\") == \"sequence\":\n#                 guess_info.append(\"- Password has sequential characters\")\n\n#     if entropy < 30:\n#         guess_info.append(\"- Password has low entropy\")\n#     if not any(c in pw for c in \"!@#$%^&*()_+-=[]{}|;:,.<>?/\"):\n#         guess_info.append(\"- Missing special characters\")\n\n#     prompt = f\"\"\"\n#         You are a security expert helping users strengthen their passwords using NIST guidelines.\n#         Here is the analysis of a weak password:\n#         Password: \"{pw}\"\n#         Entropy: {entropy:.2f}\n#         Identified Weaknesses:\n#         {chr(10).join(guess_info) or \"- None\"}\n        \n#         Zxcvbn Feedback:\n#         Warning: {warnings or \"None\"}\n#         Suggestions: {' '.join(suggestions) if suggestions else 'None'}\n        \n#         Your task:\n#         - Improve the password while keeping its original idea.\n#         - Avoid dictionary words, predictable patterns, and weak structures.\n#         - Ensure it includes uppercase, lowercase, digits, and special characters.\n#         - Ensure a uniform distribution of these character sets to increase the unpredictability of your password.\n#         - Create a password that is both **strong** and **memorable**.\n#         - Return only the improved password (no explanations).\n#         \"\"\".strip()\n\n#     return prompt","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-23T20:26:04.930898Z","iopub.execute_input":"2025-04-23T20:26:04.931271Z","iopub.status.idle":"2025-04-23T20:26:04.939468Z","shell.execute_reply.started":"2025-04-23T20:26:04.931244Z","shell.execute_reply":"2025-04-23T20:26:04.938002Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"# def generate_strong_password(weak_pw: str) -> str:\n#     \"\"\"Generate strong password from weak one using the fine-tuned model\"\"\"\n#     prompt = analyze_password(weak_pw)\n#     inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True)\n\n#     outputs = model.generate(\n#         **inputs,\n#         max_length=64,\n#         do_sample=True,\n#         top_p=0.95,\n#         top_k=50,\n#         temperature=0.8\n#     )\n#     strong_pw = tokenizer.decode(outputs[0], skip_special_tokens=True)\n#     return strong_pw.strip()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-23T20:26:50.790736Z","iopub.execute_input":"2025-04-23T20:26:50.791189Z","iopub.status.idle":"2025-04-23T20:26:50.797463Z","shell.execute_reply.started":"2025-04-23T20:26:50.791154Z","shell.execute_reply":"2025-04-23T20:26:50.796058Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"# # 2. Interactive loop\n# while True:\n#     weak = input(\"\\nEnter a weak password (or type 'exit'): \").strip()\n#     if weak.lower() == \"exit\":\n#         break\n\n#     print(\"\\nğŸ“‰ Analyzing your password...\")\n#     original_feedback = zxcvbn(weak)\n#     print(f\"Original Entropy: {original_feedback['guesses_log10']:.2f}\")\n#     print(f\"Score: {original_feedback['score']}/4\")\n\n#     # 3-5. Generate stronger version\n#     strong = generate_strong_password(weak)\n#     print(f\"\\nğŸ” Suggested Strong Password: {strong}\")\n\n#     # 6. Re-analyze new password\n#     new_feedback = zxcvbn(strong)\n#     print(f\"\\nğŸ“ˆ Improved Entropy: {new_feedback['guesses_log10']:.2f}\")\n#     print(f\"New Score: {new_feedback['score']}/4\")\n#     print(\"-\" * 40)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-23T20:26:52.013305Z","iopub.execute_input":"2025-04-23T20:26:52.013655Z","iopub.status.idle":"2025-04-23T20:30:46.453900Z","shell.execute_reply.started":"2025-04-23T20:26:52.013631Z","shell.execute_reply":"2025-04-23T20:30:46.452961Z"}},"outputs":[{"output_type":"stream","name":"stdin","text":"\nEnter a weak password (or type 'exit'):  password\n"},{"name":"stdout","text":"\nğŸ“‰ Analyzing your password...\nOriginal Entropy: 0.48\nScore: 0/4\n\nğŸ” Suggested Strong Password: f3rt3u4ng\n\nğŸ“ˆ Improved Entropy: 9.00\nNew Score: 3/4\n----------------------------------------\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"\nEnter a weak password (or type 'exit'):  aman\n"},{"name":"stdout","text":"\nğŸ“‰ Analyzing your password...\nOriginal Entropy: 3.89\nScore: 1/4\n\nğŸ” Suggested Strong Password: A1m0n$s\n\nğŸ“ˆ Improved Entropy: 7.00\nNew Score: 2/4\n----------------------------------------\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"\nEnter a weak password (or type 'exit'):  ram\n"},{"name":"stdout","text":"\nğŸ“‰ Analyzing your password...\nOriginal Entropy: 3.00\nScore: 0/4\n\nğŸ” Suggested Strong Password: RamR0s$@nt\n\nğŸ“ˆ Improved Entropy: 9.57\nNew Score: 3/4\n----------------------------------------\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"\nEnter a weak password (or type 'exit'):  rohit@1234\n"},{"name":"stdout","text":"\nğŸ“‰ Analyzing your password...\nOriginal Entropy: 8.00\nScore: 3/4\n\nğŸ” Suggested Strong Password: R@h1t@1234\n\nğŸ“ˆ Improved Entropy: 8.00\nNew Score: 3/4\n----------------------------------------\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"\nEnter a weak password (or type 'exit'):  Summar@1234\n"},{"name":"stdout","text":"\nğŸ“‰ Analyzing your password...\nOriginal Entropy: 8.80\nScore: 3/4\n\nğŸ” Suggested Strong Password: s@m@@3d$$0l\n\nğŸ“ˆ Improved Entropy: 10.87\nNew Score: 4/4\n----------------------------------------\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"\nEnter a weak password (or type 'exit'):  admin\n"},{"name":"stdout","text":"\nğŸ“‰ Analyzing your password...\nOriginal Entropy: 2.85\nScore: 0/4\n\nğŸ” Suggested Strong Password: AD3n$2020\n\nğŸ“ˆ Improved Entropy: 7.61\nNew Score: 2/4\n----------------------------------------\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"\nEnter a weak password (or type 'exit'):  qwert\n"},{"name":"stdout","text":"\nğŸ“‰ Analyzing your password...\nOriginal Entropy: 2.51\nScore: 0/4\n\nğŸ” Suggested Strong Password: QwertR@T8\n\nğŸ“ˆ Improved Entropy: 7.11\nNew Score: 2/4\n----------------------------------------\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"\nEnter a weak password (or type 'exit'):  zxcvbn\n"},{"name":"stdout","text":"\nğŸ“‰ Analyzing your password...\nOriginal Entropy: 1.76\nScore: 0/4\n\nğŸ” Suggested Strong Password: Z7cvns@t\n\nğŸ“ˆ Improved Entropy: 8.00\nNew Score: 2/4\n----------------------------------------\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"\nEnter a weak password (or type 'exit'):  qwasert\n"},{"name":"stdout","text":"\nğŸ“‰ Analyzing your password...\nOriginal Entropy: 5.77\nScore: 1/4\n\nğŸ” Suggested Strong Password: QWasert@rt\n\nğŸ“ˆ Improved Entropy: 8.99\nNew Score: 3/4\n----------------------------------------\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"\nEnter a weak password (or type 'exit'):  some1G0\n"},{"name":"stdout","text":"\nğŸ“‰ Analyzing your password...\nOriginal Entropy: 5.08\nScore: 1/4\n\nğŸ” Suggested Strong Password: S0Y1G0$\n\nğŸ“ˆ Improved Entropy: 7.00\nNew Score: 2/4\n----------------------------------------\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"\nEnter a weak password (or type 'exit'):  exit\n"}],"execution_count":25},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}